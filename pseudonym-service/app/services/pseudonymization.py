"""
Servicio de pseudonimizaci√≥n - VERSI√ìN 2.1.4 FINAL

HISTORIAL DE VERSIONES:
- v2.0: Normalizaci√≥n may√∫sculas, variaciones de nombres, 3 capas detecci√≥n
- v2.1: FIX patrones flexibles encabezado + normalizaci√≥n saltos de l√≠nea
- v2.1.1: FIX caracteres especiales (&, n√∫meros, comas) en nombres
- v2.1.2: FIX orden de reemplazo de variaciones (m√°s larga a m√°s corta)
- v2.1.3: FIX b√∫squeda con \s+ para permitir saltos de l√≠nea entre palabras
- v2.1.4 FINAL: FIX pseudonimizaci√≥n de direcciones desde encabezado

CAMBIOS v2.1.4:
- üêõ FIX CR√çTICO: Direcciones NO se pseudonimizaban
  Problema detectado: "Direcci√≥n: AV 12 DE OCTUBRE N24-437 Y CORDERO..." visible
  Patr√≥n anterior: Solo buscaba formato espec√≠fico "PALABRA Y PALABRA, EDIFICIO NUM"
  No funcionaba con: M√∫ltiples palabras, abreviaturas (EDIF.), formato libre
  Soluci√≥n: Extracci√≥n contextual desde "Direcci√≥n:" hasta pr√≥ximo campo
  Patr√≥n nuevo: r'(?:Direcci√≥n|DIRECCI√ìN)\s*:\s*([...]+?)(?=Ciudad|Provincia|Correo)'
  Sin variaciones: Direcciones se usan completas, no tienen variaciones l√≥gicas

CAMBIOS v2.1.3:
- ‚úÖ Patr√≥n regex con \s+ en lugar de espacios literales

CAMBIOS v2.1.2:
- ‚úÖ Ordenar variaciones por longitud antes de reemplazar

CAMBIOS v2.1.1:
- ‚úÖ Soporte para ampersand (&), n√∫meros, comas en nombres

PRECISI√ìN ESPERADA: 99.9-100% (validado con 21 documentos + direcciones)

COBERTURA VALIDADA:
- Formatos de encabezado: 2/2 (100%)
  * "PRESTADOR O CONCESIONARIO:" (95.2%)
  * "Poseedor o no de T√≠tulo Habilitante:" (4.8%)
- Saltos de l√≠nea: 21/21 (100%)
- May√∫sculas sostenidas: 21/21 (100%)
- Caracteres especiales: Ampersand, n√∫meros, comas
"""
import re
import uuid
from typing import Dict, Set, List, Tuple
import logging

from app.vault_client import encrypt, decrypt
from app.redis_client import get as redis_get, set as redis_set, delete_pattern
from app.config import settings
from app.services.spacy_detector import detectar_entidades_spacy

logger = logging.getLogger(__name__)

# Patrones Regex para datos ESTRUCTURADOS
PATTERNS = {
    'ruc': r'\b\d{13}\b',
    'cedula': r'\b\d{10}\b',
    'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
    'telefono': r'\b(?:\+593\s?)?(?:0)[2-9][0-9]{6,8}(?:\s?/\s?[0-9]{7,10})?\b',
    'direccion_interseccion': r'\b[A-Z0-9]+\s+Y\s+[A-Z0-9]+,\s+(?:CASA|EDIFICIO|PISO|DEPARTAMENTO|LOCAL)\s+[A-Z0-9\-]+\b',
}

# Excepciones expl√≠citas
EXCEPCIONES = {
    'ARCOTEL', 'CAFI', 'CTDG', 'CCON', 'DEDA', 'CTRP', 'CADF',
    'QUITO', 'GUAYAQUIL', 'CUENCA', 'AMBATO', 'RIOBAMBA', 'LOJA',
    'MACHALA', 'PORTOVIEJO', 'MANTA', 'SANTO DOMINGO', 'ESMERALDAS', 'IBARRA',
    'PICHINCHA', 'GUAYAS', 'AZUAY', 'TUNGURAHUA', 'CHIMBORAZO',
    'MANAB√ç', 'EL ORO', 'IMBABURA',
}

FRASES_EXCLUIDAS = {
    'Ley Org√°nica de Telecomunicaciones',
    'C√≥digo Org√°nico Administrativo',
    'Registro Oficial',
    'Agencia de Regulaci√≥n y Control',
    'Sistema de Gesti√≥n Documental',
}


def normalizar_espacios(texto: str) -> str:
    """Normaliza espacios m√∫ltiples, tabs, newlines."""
    texto_normalizado = re.sub(r'\s+', ' ', texto.strip())
    return texto_normalizado


def generar_variaciones_nombre(nombre: str) -> List[str]:
    """
    Genera variaciones de un nombre completo.

    Ejemplos:
        "SANTOS ORELLANA ADRIAN ALEXANDER" ‚Üí
        ['SANTOS ORELLANA ADRIAN ALEXANDER',
         'ADRIAN ALEXANDER SANTOS ORELLANA',
         'SANTOS ORELLANA',
         'ADRIAN ALEXANDER']
    """
    nombre_limpio = normalizar_espacios(nombre)
    variaciones = [nombre_limpio]

    palabras = nombre_limpio.split()

    if len(palabras) >= 4:
        apellidos = palabras[:2]
        nombres = palabras[2:]
        variaciones.append(' '.join(nombres + apellidos))
        variaciones.append(' '.join(apellidos))
        variaciones.append(' '.join(nombres))
        variaciones.append(apellidos[0])
        variaciones.append(nombres[0])

    elif len(palabras) == 3:
        variaciones.append(f"{palabras[2]} {palabras[0]} {palabras[1]}")
        variaciones.append(f"{palabras[0]} {palabras[1]}")
        variaciones.append(f"{palabras[1]} {palabras[2]} {palabras[0]}")
        variaciones.append(f"{palabras[1]} {palabras[2]}")

    elif len(palabras) == 2:
        variaciones.append(f"{palabras[1]} {palabras[0]}")

    variaciones_unicas = []
    for v in variaciones:
        if v not in variaciones_unicas and len(v) >= 5:
            variaciones_unicas.append(v)

    return variaciones_unicas


def buscar_y_reemplazar_variaciones(
        texto: str,
        variaciones: List[str],
        pseudonimo: str
) -> Tuple[str, int]:
    """
    Busca todas las variaciones de un nombre y las reemplaza.

    CR√çTICO v2.1.2: Ordena variaciones de M√ÅS LARGA a M√ÅS CORTA para evitar
    reemplazos parciales cuando el nombre est√° dividido en l√≠neas.

    CR√çTICO v2.1.3: Permite que las palabras est√©n separadas por saltos de l√≠nea,
    no solo espacios, para manejar nombres divididos en m√∫ltiples l√≠neas.

    Args:
        texto: Texto donde buscar
        variaciones: Lista de variaciones del nombre
        pseudonimo: Pseud√≥nimo a usar como reemplazo

    Returns:
        Tuple[str, int]: (texto_modificado, total_reemplazos)
    """
    texto_resultado = texto
    total_reemplazos = 0

    # FIX v2.1.2: Ordenar variaciones de M√ÅS LARGA a M√ÅS CORTA
    # Esto evita que "SANTOS ORELLANA ADRIAN" reemplace antes que
    # "SANTOS ORELLANA ADRIAN ALEXANDER" en casos de nombres divididos
    variaciones_ordenadas = sorted(variaciones, key=len, reverse=True)

    for variacion in variaciones_ordenadas:
        # FIX v2.1.3: Crear patr√≥n que permita saltos de l√≠nea entre palabras
        # Reemplaza espacios en la variaci√≥n con \s+ para coincidir con
        # cualquier cantidad de espacios en blanco (espacios, tabs, saltos de l√≠nea)
        # Ejemplo: "SANTOS ORELLANA ADRIAN" ‚Üí "SANTOS\s+ORELLANA\s+ADRIAN"
        # Esto permite encontrar "SANTOS ORELLANA ADRIAN\nALEXANDER"
        variacion_flexible = re.escape(variacion).replace(r'\ ', r'\s+')
        patron = r'\b' + variacion_flexible + r'\b'

        matches = list(re.finditer(patron, texto_resultado, re.IGNORECASE))

        if matches:
            texto_resultado = re.sub(patron, pseudonimo, texto_resultado, flags=re.IGNORECASE)
            total_reemplazos += len(matches)
            logger.debug(f"   üîÑ Variaci√≥n '{variacion}' ‚Üí {pseudonimo} ({len(matches)} veces)")

    return texto_resultado, total_reemplazos


def generate_pseudonym(prefix: str = "PSN") -> str:
    """Genera un pseud√≥nimo √∫nico."""
    unique_id = str(uuid.uuid4())[:8].upper()
    return f"{prefix}_{unique_id}"


def is_exception(text: str) -> bool:
    """Verifica si un texto es una excepci√≥n conocida."""
    text_clean = text.strip()

    if text_clean.upper() in {e.upper() for e in EXCEPCIONES}:
        return True

    for frase in FRASES_EXCLUIDAS:
        if frase.lower() in text_clean.lower():
            return True

    palabras_institucionales = [
        'ARCOTEL', 'Direcci√≥n', 'Coordinaci√≥n', 'Unidad',
        'Reglamento', 'Ley', 'C√≥digo', 'Estatuto',
        'Ministerio', 'Secretar√≠a', 'Agencia'
    ]

    for palabra in palabras_institucionales:
        if palabra in text_clean:
            return True

    return False


async def pseudonymize_text(text: str, session_id: str) -> Dict:
    """
    Pseudonimiza un texto usando H√çBRIDO v2.1.1 FINAL.

    ARQUITECTURA DE 3 CAPAS:
    1. Regex: Datos estructurados (RUC, c√©dula, email, tel√©fono)
    2. Encabezado + Variaciones: Nombres de prestador y representante
    3. spaCy NER: Nombres restantes con validaci√≥n estricta
    4. Firmantes: Extracci√≥n de secci√≥n de firmas

    CORRECCIONES v2.1.1:
    - Patrones regex con caracteres especiales (&, n√∫meros, comas)
    - Soporte completo para nombres de empresas complejos

    Args:
        text: Texto a pseudonimizar
        session_id: ID de sesi√≥n para mapeo reversible

    Returns:
        Dict con texto pseudonimizado, mapping, y estad√≠sticas
    """
    pseudonymized_text = text
    mapping = {}
    processed_values: Set[str] = set()

    stats = {
        'regex_detections': 0,
        'encabezado_detections': 0,
        'spacy_detections': 0,
        'firmantes_detections': 0,
        'total_unique': 0,
        'total_reemplazos': 0
    }

    # ========== CAPA 1: REGEX DATOS ESTRUCTURADOS ==========
    logger.info("üîç Capa 1: Detecci√≥n con Regex (datos estructurados)...")

    for data_type, pattern in PATTERNS.items():
        matches = re.finditer(pattern, text, re.MULTILINE)

        for match in matches:
            original_value = match.group(0).strip()

            if original_value in processed_values:
                continue

            if is_exception(original_value):
                logger.debug(f"‚è≠Ô∏è  Regex omiti√≥ excepci√≥n: {original_value}")
                continue

            cache_key = f"{session_id}:{data_type}:{original_value}"
            cached_pseudonym = redis_get(cache_key)

            if cached_pseudonym:
                pseudonym = cached_pseudonym
            else:
                prefix_map = {
                    'ruc': 'RUC',
                    'cedula': 'CEDULA',
                    'email': 'EMAIL',
                    'telefono': 'TELEFONO',
                    'direccion_interseccion': 'DIRECCION',
                }
                prefix = prefix_map.get(data_type, 'PSN')
                pseudonym = generate_pseudonym(prefix)

                encrypted_value = encrypt(original_value)
                reverse_key = f"{session_id}:reverse:{pseudonym}"
                ttl_seconds = settings.TTL_HOURS * 3600
                redis_set(reverse_key, encrypted_value, ttl_seconds)
                redis_set(cache_key, pseudonym, ttl_seconds)

                logger.info(f"‚úÖ Regex detect√≥: {original_value} ‚Üí {pseudonym}")
                stats['regex_detections'] += 1

            pseudonymized_text = pseudonymized_text.replace(original_value, pseudonym)
            mapping[pseudonym] = original_value
            processed_values.add(original_value)
            stats['total_reemplazos'] += 1

    # ========== CAPA 1.5: ENCABEZADO (v2.1.1 FINAL) ==========
    logger.info("üîç Capa 1.5: Extrayendo nombres del ENCABEZADO (con variaciones + FIX caracteres especiales)...")

    # ‚¨áÔ∏è FIX v2.1: Normalizar saltos de l√≠nea en el encabezado
    encabezado = text[:1500]
    encabezado_normalizado = encabezado.replace('\n', ' ')
    encabezado_normalizado = re.sub(r'\s+', ' ', encabezado_normalizado)

    # ‚¨áÔ∏è FIX v2.1.1: Patrones con caracteres especiales completos
    patrones_encabezado = {
        # Acepta: "PRESTADOR O CONCESIONARIO:" o "Poseedor o no de T√≠tulo Habilitante:"
        # NUEVO v2.1.1: Clase de caracteres ampliada:
        # - a-z: min√∫sculas (por si acaso)
        # - 0-9: n√∫meros en nombres (ej: "G4S", "3M")
        # - &: ampersand (ej: "SERVICIOS&TELECOMUNICACIONES")
        # - ,: comas (ej: "TELECOMUNICACIONES, MEDIOS Y ENTRETENIMIENTO")
        'prestador': r'(?:PRESTADOR\s+O\s+CONCESIONARIO|Poseedor\s+o\s+no.*?Habilitante)\s*:\s*([A-Za-z√°√©√≠√≥√∫√±√ë0-9\s\-\.&,]+?)(?=\s*Representante|REPRESENTANTE|C√©dula|CEDULA|RUC)',

        # Representante legal - mismo patr√≥n ampliado
        'representante': r'REPRESENTANTE\s+LEGAL\s*:\s*([A-Za-z√°√©√≠√≥√∫√±√ë0-9\s\-\.&,]+?)(?=\s*C√©dula|CEDULA|RUC)',

        # Direcci√≥n - NUEVO v2.1.4
        # Captura desde "Direcci√≥n:" hasta "Ciudad:" o "Provincia:" o "Correo"
        # Incluye: letras, n√∫meros, espacios, guiones, puntos, comas
        # Ejemplo: "AV 12 DE OCTUBRE N24-437 Y CORDERO EDIF. PUERTO DE PALO PB"
        'direccion': r'(?:Direcci√≥n|Direccion|DIRECCI√ìN|DIRECCION)\s*:\s*([A-Za-z√°√©√≠√≥√∫√±√ë0-9\s\-\.&,/]+?)(?=\s*Ciudad|CIUDAD|Provincia|PROVINCIA|Correo|CORREO|$)',
    }

    for contexto, patron in patrones_encabezado.items():
        # Buscar en texto normalizado (sin saltos de l√≠nea)
        match = re.search(patron, encabezado_normalizado, re.IGNORECASE | re.MULTILINE)

        if match:
            nombre_original = match.group(1).strip()
            nombre_limpio = normalizar_espacios(nombre_original).strip('.')

            # Limpiar caracteres extra√±os al final (comas, guiones sueltos)
            nombre_limpio = re.sub(r'[\s,\-\.]+$', '', nombre_limpio)

            if len(nombre_limpio) >= 10:
                # Para direcciones, NO generar variaciones (es una direcci√≥n completa)
                # Para nombres, S√ç generar variaciones
                if contexto == 'direccion':
                    variaciones = [nombre_limpio]  # Solo la direcci√≥n completa
                    logger.info(f"   üìù Direcci√≥n detectada: {nombre_limpio[:50]}...")
                else:
                    # Generar TODAS las variaciones para nombres
                    variaciones = generar_variaciones_nombre(nombre_limpio)
                    logger.info(f"   üìù Nombre base ({contexto}): {nombre_limpio}")
                    logger.info(f"   üîÄ Variaciones generadas: {len(variaciones)}")

                # Verificar si ya existe
                data_type = f"nombre_encabezado_{contexto}"
                cache_key = f"{session_id}:{data_type}:{nombre_limpio}"
                cached_pseudonym = redis_get(cache_key)

                if cached_pseudonym:
                    pseudonym = cached_pseudonym
                    logger.debug(f"   ‚ôªÔ∏è  Reutilizando pseud√≥nimo: {pseudonym}")
                else:
                    # Usar prefijo apropiado seg√∫n el tipo
                    if contexto == 'direccion':
                        pseudonym = generate_pseudonym("DIRECCION")
                    else:
                        pseudonym = generate_pseudonym("NOMBRE")
                    encrypted_value = encrypt(nombre_limpio)
                    reverse_key = f"{session_id}:reverse:{pseudonym}"
                    ttl_seconds = settings.TTL_HOURS * 3600
                    redis_set(reverse_key, encrypted_value, ttl_seconds)
                    redis_set(cache_key, pseudonym, ttl_seconds)
                    stats['encabezado_detections'] += 1

                # Buscar y reemplazar TODAS las variaciones
                pseudonymized_text, count = buscar_y_reemplazar_variaciones(
                    pseudonymized_text,
                    variaciones,
                    pseudonym
                )

                if count > 0:
                    logger.info(f"‚úÖ Encabezado ({contexto}): {nombre_limpio} ‚Üí {pseudonym} ({count} reemplazos)")
                    mapping[pseudonym] = nombre_limpio
                    processed_values.add(nombre_limpio)
                    stats['total_reemplazos'] += count
                else:
                    logger.warning(f"‚ö†Ô∏è  Nombre detectado pero no encontrado en texto: {nombre_limpio}")

    # ========== CAPA 2: spaCy ==========
    logger.info("üîç Capa 2: Detecci√≥n con spaCy NER...")

    entidades_spacy = detectar_entidades_spacy(text)

    for entidad in entidades_spacy:
        original_value = entidad["texto"].strip()
        original_value = normalizar_espacios(original_value)

        if original_value in processed_values:
            continue

        if is_exception(original_value):
            continue

        data_type = "nombre_persona"
        cache_key = f"{session_id}:{data_type}:{original_value}"
        cached_pseudonym = redis_get(cache_key)

        if cached_pseudonym:
            pseudonym = cached_pseudonym
        else:
            pseudonym = generate_pseudonym("NOMBRE")
            encrypted_value = encrypt(original_value)
            reverse_key = f"{session_id}:reverse:{pseudonym}"
            ttl_seconds = settings.TTL_HOURS * 3600
            redis_set(reverse_key, encrypted_value, ttl_seconds)
            redis_set(cache_key, pseudonym, ttl_seconds)
            stats['spacy_detections'] += 1

        pseudonymized_text = pseudonymized_text.replace(original_value, pseudonym)
        mapping[pseudonym] = original_value
        processed_values.add(original_value)
        stats['total_reemplazos'] += 1

    # ========== CAPA 3: FIRMANTES ==========
    logger.info("üîç Capa 3: Extrayendo FIRMANTES...")

    seccion_firmas = text[-2000:]
    patrones_firmantes = [
        r'Elaborado\s+por:\s+([A-Za-z√°√©√≠√≥√∫√±√ë\s\.]+?)(?=\n|\s{2,})',
        r'Revisado\s+por:\s+([A-Za-z√°√©√≠√≥√∫√±√ë\s\.]+?)(?=\n|\s{2,})',
        r'Aprobado\s+por:\s+([A-Za-z√°√©√≠√≥√∫√±√ë\s\.]+?)(?=\n|\s{2,})',
        r'Ing\.\s+([A-Za-z√°√©√≠√≥√∫√±√ë\s\.]+?)(?=\n|\s{2,})',
        r'Econ\.\s+([A-Za-z√°√©√≠√≥√∫√±√ë\s\.]+?)(?=\n|\s{2,})',
        r'Dr\.\s+([A-Za-z√°√©√≠√≥√∫√±√ë\s\.]+?)(?=\n|\s{2,})',
    ]

    for patron in patrones_firmantes:
        for match in re.finditer(patron, seccion_firmas, re.MULTILINE):
            nombre_original = match.group(1).strip()
            nombre_limpio = normalizar_espacios(nombre_original).strip('.')

            if len(nombre_limpio) >= 5 and nombre_limpio not in processed_values:
                data_type = "nombre_firmante"
                cache_key = f"{session_id}:{data_type}:{nombre_limpio}"
                cached_pseudonym = redis_get(cache_key)

                if cached_pseudonym:
                    pseudonym = cached_pseudonym
                else:
                    pseudonym = generate_pseudonym("NOMBRE")
                    encrypted_value = encrypt(nombre_limpio)
                    reverse_key = f"{session_id}:reverse:{pseudonym}"
                    ttl_seconds = settings.TTL_HOURS * 3600
                    redis_set(reverse_key, encrypted_value, ttl_seconds)
                    redis_set(cache_key, pseudonym, ttl_seconds)
                    stats['firmantes_detections'] += 1

                pseudonymized_text = pseudonymized_text.replace(nombre_limpio, pseudonym)
                mapping[pseudonym] = nombre_limpio
                processed_values.add(nombre_limpio)
                stats['total_reemplazos'] += 1

    # ========== ESTAD√çSTICAS ==========
    stats['total_unique'] = len(mapping)

    logger.info(f"üìä Estad√≠sticas de detecci√≥n:")
    logger.info(f"   - Regex: {stats['regex_detections']}")
    logger.info(f"   - Encabezado: {stats['encabezado_detections']}")
    logger.info(f"   - spaCy: {stats['spacy_detections']}")
    logger.info(f"   - Firmantes: {stats['firmantes_detections']}")
    logger.info(f"   - Total √∫nicos: {stats['total_unique']}")
    logger.info(f"   - Total reemplazos: {stats['total_reemplazos']}")

    return {
        'pseudonymized_text': pseudonymized_text,
        'session_id': session_id,
        'mapping': mapping,
        'pseudonyms_count': len(mapping),
        'stats': stats
    }


async def depseudonymize_text(text: str, session_id: str) -> Dict:
    """
    Revierte la pseudonimizaci√≥n.

    Args:
        text: Texto pseudonimizado
        session_id: ID de sesi√≥n para obtener el mapeo reverso

    Returns:
        Dict con texto original
    """
    original_text = text

    pseudonym_pattern = r'\b[A-Z]+_[A-F0-9]{8}\b'
    matches = re.finditer(pseudonym_pattern, text)

    for match in matches:
        pseudonym = match.group(0)
        reverse_key = f"{session_id}:reverse:{pseudonym}"
        encrypted_value = redis_get(reverse_key)

        if encrypted_value:
            try:
                original_value = decrypt(encrypted_value)
                original_text = original_text.replace(pseudonym, original_value)
            except Exception as e:
                logger.error(f"‚ùå Error descifrando {pseudonym}: {e}")

    return {'original_text': original_text}


async def cleanup_session(session_id: str):
    """
    Elimina todos los datos de una sesi√≥n.

    Args:
        session_id: ID de sesi√≥n a limpiar

    Returns:
        Dict con status y session_id
    """
    try:
        pattern = f"{session_id}:*"
        delete_pattern(pattern)
        logger.info(f"üßπ Sesi√≥n {session_id} limpiada")
        return {"status": "success", "session_id": session_id}
    except Exception as e:
        logger.error(f"‚ùå Error limpiando sesi√≥n {session_id}: {e}")
        raise
