"""
Detector de entidades nombradas usando spaCy NER - VERSI√ìN MEJORADA

MEJORAS:
- Normalizaci√≥n de MAY√öSCULAS SOSTENIDAS antes de pasar a spaCy
- Validaci√≥n estricta de nombres para evitar falsos positivos
- Detecci√≥n mejorada de nombres en documentos ARCOTEL

SOLO DETECTA PERSONAS (PER) con validaci√≥n estricta:
- T√≠tulos profesionales: Ing., Dr., Econ., Abg., etc.
- Apellidos en may√∫sculas
- Longitud 10-60 caracteres
- Rechaza verbos, palabras institucionales, y t√©rminos gen√©ricos

Las ubicaciones espec√≠ficas se detectan con Regex (direcciones, intersecciones).
"""
import spacy
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

# Cargar modelo una sola vez (al iniciar el servicio)
try:
    nlp = spacy.load("es_core_news_lg")
    logger.info("‚úÖ Modelo spaCy LARGE cargado correctamente")
except Exception as e:
    logger.error(f"‚ùå Error cargando spaCy: {e}")
    nlp = None


def normalizar_mayusculas(texto: str) -> str:
    """
    Normaliza MAY√öSCULAS SOSTENIDAS a Title Case para mejorar detecci√≥n de spaCy.

    Ejemplo:
        "CHARCO I√ëIGUEZ KLEVER LUIS trabaja en ARCOTEL"
        ‚Üí "Charco I√±iguez Klever Luis trabaja en ARCOTEL"

    IMPORTANTE: Mantiene siglas conocidas (ARCOTEL, SAI, GFC, etc.)

    Args:
        texto: Texto con may√∫sculas sostenidas

    Returns:
        str: Texto normalizado
    """
    # Siglas y acr√≥nimos que NO deben normalizarse
    SIGLAS_CONOCIDAS = {
        'ARCOTEL', 'SAI', 'GFC', 'CTDG', 'CCON', 'DEDA', 'CTRP', 'CADF',
        'RUC', 'LOT', 'COA', 'USD', 'ROTH', 'TH', 'PAS', 'NER', 'IA', 'AI',
        'PDF', 'HTML', 'API', 'HTTP', 'HTTPS', 'URL', 'XML', 'JSON',
        'CAFI', 'SGD', 'CZ2', 'QUITO', 'GUAYAQUIL', 'CUENCA'
    }

    palabras = texto.split()
    palabras_normalizadas = []

    for palabra in palabras:
        palabra_limpia = palabra.strip('.,;:()[]{}')

        # Mantener siglas conocidas
        if palabra_limpia in SIGLAS_CONOCIDAS:
            palabras_normalizadas.append(palabra)
        # Normalizar palabras largas en may√∫sculas
        elif palabra_limpia.isupper() and len(palabra_limpia) > 2 and palabra_limpia.isalpha():
            # Preservar puntuaci√≥n al final
            sufijo = palabra[len(palabra_limpia):]
            palabras_normalizadas.append(palabra_limpia.title() + sufijo)
        else:
            palabras_normalizadas.append(palabra)

    return ' '.join(palabras_normalizadas)


def detectar_entidades_spacy(texto: str) -> List[Dict]:
    """
    Detecta entidades nombradas usando spaCy NER.

    SOLO DETECTA PERSONAS (PER), ignora ubicaciones (LOC).
    Las ubicaciones espec√≠ficas ya se detectan con Regex.

    MEJORA: Normaliza MAY√öSCULAS antes de pasar a spaCy para mejor detecci√≥n.

    Args:
        texto: Texto a analizar

    Returns:
        List[Dict]: Lista de PERSONAS detectadas y validadas
    """
    if not nlp:
        logger.warning("‚ö†Ô∏è spaCy no disponible, retornando lista vac√≠a")
        return []

    try:
        # ===== NUEVO: NORMALIZACI√ìN DE MAY√öSCULAS =====
        texto_normalizado = normalizar_mayusculas(texto)
        logger.debug(f"üìù Texto normalizado para spaCy")

        # Aplicar spaCy al texto normalizado
        doc = nlp(texto_normalizado)
        entidades = []

        for ent in doc.ents:
            # ===== SOLO PERSONAS (PER) =====
            if ent.label_ != "PER":
                continue

            # Validaci√≥n estricta para nombres
            if not es_nombre_real(ent.text):
                logger.debug(f"‚è≠Ô∏è spaCy rechaz√≥ nombre: {ent.text}")
                continue

            # Si pas√≥ las validaciones, agregar
            entidades.append({
                "texto": ent.text,
                "tipo": ent.label_,
                "inicio": ent.start_char,
                "fin": ent.end_char
            })

        logger.info(
            f"‚úÖ spaCy detect√≥ {len(entidades)} PERSONAS validadas (de {len([e for e in doc.ents if e.label_ == 'PER'])} personas totales)")
        return entidades

    except Exception as e:
        logger.error(f"‚ùå Error en detecci√≥n spaCy: {e}")
        return []


def es_nombre_real(texto: str) -> bool:
    """
    Verifica si un texto detectado por spaCy es realmente un nombre personal.

    FILTROS ESTRICTOS para evitar falsos positivos.

    Args:
        texto: Texto a verificar

    Returns:
        bool: True si parece un nombre real
    """
    # Palabras que indican que NO es un nombre personal
    palabras_institucionales = {
        'direcci√≥n', 'coordinaci√≥n', 'unidad', 't√©cnica', 'administrativa',
        'financiera', 'gesti√≥n', 'control', 'registro', 'agencia',
        'ministerio', 'secretar√≠a', 'departamento', 'divisi√≥n',
        'ley', 'reglamento', 'c√≥digo', 'estatuto', 'manual',
        'servicio', 'sistema', 'procedimiento', 'proceso',
        'arcotel', 'telecomunicaciones', 't√≠tulos', 'habilitantes',
        'org√°nica', 'administrativo', 'sancionador', 'certificaci√≥n',
        'remisi√≥n', 'elaborar', 'certifico', 'certificar', 'quinta',
        'documental', 'quipux', 'equinoccial', 'provincia'
    }

    # Verbos comunes que NO son nombres
    verbos = {
        'elaborar', 'certificar', 'certifico', 'remitir', 'enviar',
        'solicitar', 'aprobar', 'rechazar', 'validar', 'verificar'
    }

    # Convertir a min√∫sculas para comparaci√≥n
    texto_lower = texto.lower()
    texto_clean = texto.strip()

    # FILTRO 1: Contiene palabras institucionales
    for palabra in palabras_institucionales:
        if palabra in texto_lower:
            return False

    # FILTRO 2: Contiene verbos
    for verbo in verbos:
        if verbo in texto_lower:
            return False

    # FILTRO 3: Debe tener al menos 2 palabras completas
    palabras = texto_clean.split()
    if len(palabras) < 2:
        return False

    # FILTRO 4: M√°ximo 5 palabras (nombres muy largos son sospechosos)
    if len(palabras) > 5:
        return False

    # FILTRO 5: Longitud razonable (entre 10 y 60 caracteres)
    # M√°s estricto que antes
    if len(texto_clean) < 10 or len(texto_clean) > 60:
        return False

    # FILTRO 6: Debe contener al menos un t√≠tulo profesional o apellido t√≠pico
    # Si empieza con Ing., Dr., Econ., Abg., etc. es m√°s probable que sea nombre real
    titulos = ['ing.', 'dr.', 'econ.', 'abg.', 'msc.', 'phd.', 'mgtr.', 'lic.']
    tiene_titulo = any(titulo in texto_lower for titulo in titulos)

    # FILTRO 7: No debe contener caracteres sospechosos
    caracteres_invalidos = ['‚Üí', '‚Üê', '‚Ä¢', '‚óã', '‚óè', '\n', '\t']
    for char in caracteres_invalidos:
        if char in texto_clean:
            return False

    # FILTRO 8: No debe tener palabras cortadas (menos de 3 caracteres sin t√≠tulo)
    for palabra in palabras:
        palabra_limpia = palabra.strip('.,;:')
        # Ignorar t√≠tulos cortos y conectores
        if palabra_limpia.lower() not in ['ing', 'dr', 'sr', 'sra', 'ab', 'de', 'la', 'y']:
            if len(palabra_limpia) < 3:
                return False

    # FILTRO 9: Debe tener apellidos (palabras en may√∫scula sostenida) o t√≠tulo
    # NOTA: Esto ahora es m√°s flexible gracias a la normalizaci√≥n
    palabras_mayusculas = sum(1 for p in palabras if p.isupper() and len(p) > 3)

    # Si tiene t√≠tulo profesional, es muy probable que sea nombre real
    if tiene_titulo and len(palabras) >= 2:
        return True

    # Sin t√≠tulo, debe tener al menos 2 palabras (apellido + nombre)
    # Con la normalizaci√≥n, ya no necesitamos palabras en may√∫scula
    if len(palabras) >= 2:
        return True

    # Rechazar todo lo dem√°s
    return False
